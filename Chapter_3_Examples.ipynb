{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62cc8ad9",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wooihaw/ERA3036_T2310/blob/main/Chapter_3/Chapter_3_Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efde6f2-c53b-437f-97e2-5dc67c4d8715",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "### Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ac57ea-5649-4ce7-a213-cc98312e78b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries for pipeline creation, model selection, and preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split as split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "# Loading the breast cancer dataset\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and test sets, with stratification to ensure representative class distribution\n",
    "X_train, X_test, y_train, y_test = split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Without pipeline\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "print(f\"Without pipeline: {knn.score(X_test, y_test):.3%}\")\n",
    "\n",
    "# Creating a pipeline with a scaler (None initially), feature selector, and classifier\n",
    "pipe = Pipeline([('scl', None), ('fs', SelectKBest()), ('clf', KNeighborsClassifier())])\n",
    "\n",
    "# Creating a parameter grid to search for the best parameters for preprocessing and the classifier\n",
    "params = {}\n",
    "params['scl'] = [None, MinMaxScaler(), StandardScaler(), RobustScaler()]  # Different scalers\n",
    "params['fs__k'] = range(10, 20)  # Number of features to select\n",
    "params['clf'] = [KNeighborsClassifier(), LogisticRegression(), DecisionTreeClassifier()]  # Classifier options\n",
    "\n",
    "# Setting up the grid search with cross-validation to find the best parameters\n",
    "gs = GridSearchCV(pipe, params, cv=5, n_jobs=-1, verbose=2)\n",
    "gs.fit(X_train, y_train)  # Note: This should be X_train, y_train instead of X_trainval, y_trainval\n",
    "\n",
    "# Printing the best parameters found by the grid search\n",
    "print(gs.best_params_)\n",
    "\n",
    "# Printing the score of the best model on the test set\n",
    "print(f\"With pipeline: {gs.score(X_test, y_test):.3%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aa5b81-025a-4d0e-9020-34feffdc2eee",
   "metadata": {
    "id": "08aa5b81-025a-4d0e-9020-34feffdc2eee"
   },
   "source": [
    "## Example 2\n",
    "### Movie Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5239159f-7d23-4ed5-9b5b-97ff55847b93",
   "metadata": {
    "id": "5239159f-7d23-4ed5-9b5b-97ff55847b93"
   },
   "outputs": [],
   "source": [
    "# Load movie reviews\n",
    "import sys\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(\"https://raw.githubusercontent.com/wooihaw/datasets/main/movie_reviews.zip\")\n",
    "\n",
    "# Ensure the request was successful\n",
    "if response.status_code == 200:\n",
    "  # Determine the environment\n",
    "  is_colab = 'google.colab' in sys.modules\n",
    "  # # Load the dataset conditionally\n",
    "  if is_colab:\n",
    "    # Code for Google Colab environment\n",
    "    moviedir = 'sample_data/movie_reviews'\n",
    "    zipfile = ZipFile(BytesIO(response.content))\n",
    "    zipfile.extractall(\"sample_data/\")\n",
    "  else:\n",
    "     # Code for local Jupyter Notebook environment\n",
    "    moviedir = '../data/movie_reviews/'\n",
    "    zipfile = ZipFile(BytesIO(response.content))\n",
    "    zipfile.extractall(\"../data/\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the file\")\n",
    "\n",
    "movies = load_files(moviedir, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75dae1-45a2-4642-b33e-01734c7afb54",
   "metadata": {
    "id": "4c75dae1-45a2-4642-b33e-01734c7afb54"
   },
   "outputs": [],
   "source": [
    "# target names (\"classes\") are automatically generated from subfolder names\n",
    "print(movies.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6689d9c8-a565-44a7-ab96-e39f05c8c66c",
   "metadata": {
    "id": "6689d9c8-a565-44a7-ab96-e39f05c8c66c"
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(movies.data, movies.target, test_size = 0.20, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0fdae5-32f0-4b3b-8bd9-a420e099031f",
   "metadata": {
    "id": "3b0fdae5-32f0-4b3b-8bd9-a420e099031f"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "movieVzer = CountVectorizer(min_df=2, ngram_range=(1, 2))\n",
    "\n",
    "# fit and tranform using training text\n",
    "docs_train_counts = movieVzer.fit_transform(docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c886e2-8b12-4db7-a413-a72756e3995e",
   "metadata": {
    "id": "54c886e2-8b12-4db7-a413-a72756e3995e"
   },
   "outputs": [],
   "source": [
    "# Convert raw frequency counts into TF-IDF values\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "movieTfmer = TfidfTransformer(use_idf=True)\n",
    "docs_train_tfidf = movieTfmer.fit_transform(docs_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8eff32-b568-45d9-83c6-bf6dc5847981",
   "metadata": {
    "id": "0b8eff32-b568-45d9-83c6-bf6dc5847981"
   },
   "outputs": [],
   "source": [
    "# Using the fitted vectorizer and transformer, tranform the test data\n",
    "docs_test_counts = movieVzer.transform(docs_test)\n",
    "docs_test_tfidf = movieTfmer.transform(docs_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a4b386-23b6-410d-97dc-0ce56bc4ac77",
   "metadata": {
    "id": "86a4b386-23b6-410d-97dc-0ce56bc4ac77"
   },
   "outputs": [],
   "source": [
    "# Load Multinominal Naive Bayes classier from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6595d4-2509-4508-8d90-f38b0a63a9da",
   "metadata": {
    "id": "5a6595d4-2509-4508-8d90-f38b0a63a9da"
   },
   "outputs": [],
   "source": [
    "# Train a Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(docs_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987bab5d-7676-4998-8ad7-d9aed279bb07",
   "metadata": {
    "id": "987bab5d-7676-4998-8ad7-d9aed279bb07"
   },
   "outputs": [],
   "source": [
    "# Predict the Test set results, find accuracy\n",
    "clf.score(docs_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53353f-7aae-4de4-9585-5e67ae86c7fa",
   "metadata": {
    "id": "cd53353f-7aae-4de4-9585-5e67ae86c7fa"
   },
   "outputs": [],
   "source": [
    "# Test with short movie reviews\n",
    "reviews_new = ['This movie was excellent', 'Absolute joy ride',\n",
    "               'Tom Hanks was amazing', 'Tom Cruise shone through.',\n",
    "              'This is a huge letdown', 'Two thumbs up', 'I fell asleep halfway through',\n",
    "              \"Can't wait for the sequel\", 'I cannot recommend this highly enough',\n",
    "              'Instant classic.', 'Tom Hanks performance was Oscar-worthy.',\n",
    "              'A must-see event for all moviegoers',\n",
    "               \"Endgame isn't a great movie, but there are flashes of greatness in it\"]\n",
    "\n",
    "reviews_new_counts = movieVzer.transform(reviews_new)         # turn text into count vector\n",
    "reviews_new_tfidf = movieTfmer.transform(reviews_new_counts)  # turn into tfidf vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3de8b3-bc6d-4414-a0e0-6350920a7c90",
   "metadata": {
    "id": "db3de8b3-bc6d-4414-a0e0-6350920a7c90"
   },
   "outputs": [],
   "source": [
    "# have classifier make a prediction\n",
    "pred = clf.predict(reviews_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c95c2-6819-460b-b1d1-34c26b1c280e",
   "metadata": {
    "id": "a99c95c2-6819-460b-b1d1-34c26b1c280e"
   },
   "outputs": [],
   "source": [
    "# print out results\n",
    "for review, category in zip(reviews_new, pred):\n",
    "    print('%r => %s' % (review, movies.target_names[category]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
